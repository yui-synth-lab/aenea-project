# Aenea Configuration Example

# ============================================================================
# AI Model API Keys
# ============================================================================

# OpenAI API Key (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Google Gemini API Key
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama Base URL (optional, defaults to http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Default AI Provider Configuration (legacy, for backward compatibility)
# ============================================================================

# Options: 'mock', 'ollama', 'google', 'openai', 'anthropic'
AI_PROVIDER=ollama
AI_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# ============================================================================
# Per-Agent Model Configuration
# ============================================================================
# Each agent can have its own provider and model
# Format: AGENT_<AGENT_NAME>_PROVIDER and AGENT_<AGENT_NAME>_MODEL

# Theoria (Truth Seeker) - 慧露+観至 synthesis
AGENT_THEORIA_PROVIDER=ollama
AGENT_THEORIA_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# Pathia (Empathy Weaver) - 陽雅+結心 synthesis
AGENT_PATHIA_PROVIDER=ollama
AGENT_PATHIA_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# Kinesis (Harmony Coordinator)
AGENT_KINESIS_PROVIDER=ollama
AGENT_KINESIS_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# Aenea (User Dialogue Agent) - For direct user interaction
AGENT_AENEA_PROVIDER=ollama
AGENT_AENEA_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# System (Internal Processing) - For Compiler (S5) and Scribe (S6) stages
AGENT_SYSTEM_PROVIDER=ollama
AGENT_SYSTEM_MODEL=hf.co/LiquidAI/LFM2-2.6B-GGUF:latest

# ============================================================================
# Dialogue with Aenea Configuration
# ============================================================================
# Dedicated LLM for "Dialogue with Aenea" feature
# If not specified, defaults to AGENT_AENEA_* settings

# DIALOGUE_PROVIDER=anthropic
# DIALOGUE_MODEL=claude-3-5-sonnet-20241022

# ============================================================================
# Yui Protocol Agent Configuration (for consultation)
# ============================================================================
# When Aenea consults Yui Protocol agents, these settings override the defaults
# from yui-protocol agent files. These are inherited from Yui Protocol's own .env.

# eiro-001 (慧露) - Logical philosopher
# AGENT_EIRO_001_PROVIDER=openai
# AGENT_EIRO_001_MODEL=gpt-4o-mini
# AGENT_EIRO_001_FINALIZER_MODEL=gpt-4o-2024-08-06

# kanshi-001 (観至) - Critical observer
# AGENT_KANSHI_001_PROVIDER=anthropic
# AGENT_KANSHI_001_MODEL=claude-3-5-haiku-20241022
# AGENT_KANSHI_001_FINALIZER_MODEL=claude-sonnet-4-20250514

# hekito-001 (碧統) - Analytical synthesizer
# AGENT_HEKITO_001_PROVIDER=gemini
# AGENT_HEKITO_001_MODEL=gemini-2.5-flash
# AGENT_HEKITO_001_FINALIZER_MODEL=gemini-2.5-pro

# yoga-001 (陽雅) - Poetic visionary
# AGENT_YOGA_001_PROVIDER=anthropic
# AGENT_YOGA_001_MODEL=claude-3-5-haiku-20241022
# AGENT_YOGA_001_FINALIZER_MODEL=claude-sonnet-4-20250514

# yui-000 (結心) - Empathic harmonizer
# AGENT_YUI_000_PROVIDER=openai
# AGENT_YUI_000_MODEL=gpt-4.1-mini-2025-04-14
# AGENT_YUI_000_FINALIZER_MODEL=gpt-4.1-2025-04-14

# ============================================================================
# Server Configuration
# ============================================================================

PORT=3001

# ============================================================================
# Logging Configuration
# ============================================================================

LOG_LEVEL=INFO

# ============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# ============================================================================

# Enable/Disable RAG system (default: false)
RAG_ENABLED=false

# Embedding Model Configuration
RAG_EMBEDDING_MODEL=nomic-embed-text
RAG_EMBEDDING_BASE_URL=http://localhost:11434

# Search Configuration
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.7

# Chunking Configuration
RAG_CHUNK_SIZE=800
RAG_CHUNK_OVERLAP=100

# Vector Database Path (relative to project root)
RAG_VECTORDB_PATH=data/vectordb/aenea_vectors.db

# Knowledge Base Directories (comma-separated)
RAG_KNOWLEDGE_DIRS=knowledge/sessions,knowledge/novels,knowledge/dialogues,knowledge/theory